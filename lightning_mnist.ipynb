{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import functional as FM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MnistClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28*28, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        acc = FM.accuracy(logits, y)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        metrics = {'val_acc': acc, 'val_loss': loss}\n",
    "        self.log_dict(metrics)\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x)\n",
    "        acc = FM.accuracy(logits, y)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        metrics = {'test_acc': acc, 'test_loss': loss}\n",
    "        self.log_dict(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())\n",
    "train, val = random_split(dataset, [55000, 5000])\n",
    "test = MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type       | Params\n",
      "-------------------------------------\n",
      "0 | model | Sequential | 55.3 K\n",
      "-------------------------------------\n",
      "55.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "55.3 K    Total params\n",
      "0.221     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 59/59 [00:09<00:00,  6.51it/s, loss=0.0417, v_num=20]\n"
     ]
    }
   ],
   "source": [
    "model = MnistClassifier()\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator='gpu', devices=1)\n",
    "trainer.fit(model, DataLoader(train, batch_size=1024, num_workers=4), DataLoader(val, batch_size=1024, num_workers=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonenv\\mlenv\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1444: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `test(ckpt_path='best')` to use and best model checkpoint and avoid this warning or `ckpt_path=trainer.checkpoint_callback.last_model_path` to use the last model.\n",
      "  rank_zero_warn(\n",
      "Restoring states from the checkpoint path at c:\\Users\\lijm1\\Desktop\\Pytorch-Lightning-practice\\lightning_logs\\version_20\\checkpoints\\epoch=9-step=540.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at c:\\Users\\lijm1\\Desktop\\Pytorch-Lightning-practice\\lightning_logs\\version_20\\checkpoints\\epoch=9-step=540.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:  10%|█         | 4/40 [00:00<00:01, 33.61it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonenv\\mlenv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:01<00:00, 32.69it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc            0.9740999937057495\n",
      "        test_loss           0.08653668314218521\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_acc': 0.9740999937057495, 'test_loss': 0.08653668314218521}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(dataloaders=DataLoader(test, batch_size=256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistClassifier(\n",
       "  (model): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, argmax = torch.max(model(test[0][0][0].unsqueeze(dim=0)), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = argmax.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b64cf56e80>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"label : \" + str(test[0][1]))\n",
    "plt.imshow(test[0][0][0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4211a37325b67dc4346d743008529599135417ca8cd1eae7178b10ad33111a2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

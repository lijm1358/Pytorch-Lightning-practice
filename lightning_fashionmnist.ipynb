{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os \n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision import transforms\n",
    "from torchmetrics import functional as FM\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lightning FashionMNIST CNN 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FashionMNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())\n",
    "train, val = random_split(dataset, [55000, 5000])\n",
    "test = FashionMNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataloader = DataLoader(train, batch_size=batch_size, num_workers=2)\n",
    "val_dataloader = DataLoader(val, batch_size=batch_size, num_workers=2)\n",
    "test_dataloader = DataLoader(test, batch_size=batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5bab5c1c0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset.data[0], cmap=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*3*3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64,10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.conv(batch))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X,y = batch\n",
    "        logits = self(X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        pred = self(X)\n",
    "        val_loss = F.cross_entropy(pred, y)\n",
    "        val_acc = FM.accuracy(pred, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_acc\", val_acc)\n",
    "        return val_loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        pred = self(X)\n",
    "        acc = FM.accuracy(pred, y)\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.NAdam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | conv | Sequential | 1.1 M \n",
      "1 | fc   | Sequential | 303 K \n",
      "------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 235/235 [00:15<00:00, 15.20it/s, loss=0.236, v_num=8]\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=10, accelerator='gpu', devices=1, default_root_dir=\"./checkpoint\")\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 40/40 [00:01<00:00, 35.34it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.890500009059906\n",
      "        test_loss           0.3365372121334076\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.3365372121334076, 'test_acc': 0.890500009059906}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_from_checkpoint = Classifier.load_from_checkpoint(\"./checkpoint/lightning_logs/version_2/checkpoints/epoch=9-step=4300.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2304, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_from_checkpoint.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model_from_checkpoint(test[0][0][None, :])\n",
    "dataset.classes[pred.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e5b8f9aa30>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(dataset.classes[test[0][1]])\n",
    "plt.imshow(test[0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | conv | Sequential | 1.1 M \n",
      "1 | fc   | Sequential | 303 K \n",
      "------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 235/235 [00:14<00:00, 15.92it/s, loss=0.656, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 235/235 [00:15<00:00, 15.66it/s, loss=0.468, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.115 >= min_delta = 0.0. New best score: 0.395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 235/235 [00:14<00:00, 15.75it/s, loss=0.412, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.061 >= min_delta = 0.0. New best score: 0.334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 235/235 [00:14<00:00, 16.03it/s, loss=0.366, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.026 >= min_delta = 0.0. New best score: 0.308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 235/235 [00:14<00:00, 15.97it/s, loss=0.346, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.013 >= min_delta = 0.0. New best score: 0.295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 235/235 [00:14<00:00, 15.71it/s, loss=0.311, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 235/235 [00:17<00:00, 13.81it/s, loss=0.289, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 235/235 [00:15<00:00, 15.02it/s, loss=0.278, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.005 >= min_delta = 0.0. New best score: 0.284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 235/235 [00:16<00:00, 14.66it/s, loss=0.254, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.020 >= min_delta = 0.0. New best score: 0.264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 235/235 [00:15<00:00, 15.32it/s, loss=0.232, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.009 >= min_delta = 0.0. New best score: 0.255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 235/235 [00:14<00:00, 15.78it/s, loss=0.199, v_num=27]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 3 records. Best score: 0.255. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 235/235 [00:14<00:00, 15.77it/s, loss=0.199, v_num=27]\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "earlystop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.00, patience=3, verbose=True, mode=\"min\")\n",
    "trainer = pl.Trainer(max_epochs=50, accelerator='gpu', devices=1, enable_checkpointing=False, callbacks=[earlystop_callback])\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU()\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU()\n",
       "    (12): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=2304, out_features=128, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=64, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 20/20 [00:00<00:00, 35.59it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_acc            0.9129999876022339\n",
      "        val_loss            0.28538748621940613\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.28538748621940613, 'val_acc': 0.9129999876022339}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, dataloaders=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 짧은 모델 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train, validation, test에 5개의 batch만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params\n",
      "------------------------------------\n",
      "0 | conv | Sequential | 1.1 M \n",
      "1 | fc   | Sequential | 303 K \n",
      "------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1927: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:03<00:00,  3.45s/it, loss=2.3, v_num=]\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1, fast_dev_run=True)\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelSummary\n",
    "\n",
    "model = Classifier()\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1, callbacks=[ModelSummary(max_depth=-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name    | Type       | Params\n",
      "----------------------------------------\n",
      "0  | conv    | Sequential | 1.1 M \n",
      "1  | conv.0  | Conv2d     | 3.2 K \n",
      "2  | conv.1  | ReLU       | 0     \n",
      "3  | conv.2  | MaxPool2d  | 0     \n",
      "4  | conv.3  | Conv2d     | 73.9 K\n",
      "5  | conv.4  | ReLU       | 0     \n",
      "6  | conv.5  | Conv2d     | 147 K \n",
      "7  | conv.6  | ReLU       | 0     \n",
      "8  | conv.7  | MaxPool2d  | 0     \n",
      "9  | conv.8  | Conv2d     | 295 K \n",
      "10 | conv.9  | ReLU       | 0     \n",
      "11 | conv.10 | Conv2d     | 590 K \n",
      "12 | conv.11 | ReLU       | 0     \n",
      "13 | conv.12 | MaxPool2d  | 0     \n",
      "14 | fc      | Sequential | 303 K \n",
      "15 | fc.0    | Flatten    | 0     \n",
      "16 | fc.1    | Linear     | 295 K \n",
      "17 | fc.2    | ReLU       | 0     \n",
      "18 | fc.3    | Dropout    | 0     \n",
      "19 | fc.4    | Linear     | 8.3 K \n",
      "20 | fc.5    | ReLU       | 0     \n",
      "21 | fc.6    | Dropout    | 0     \n",
      "22 | fc.7    | Linear     | 650   \n",
      "----------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  51%|█████     | 109/215 [03:27<03:21,  1.90s/it, loss=1.05, v_num=28]]\n",
      "Epoch 9: 100%|██████████| 215/215 [00:12<00:00, 16.56it/s, loss=0.244, v_num=28]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input, output layer dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.example_input_array = torch.Tensor(32, 1, 28, 28)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*3*3, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64,10),\n",
    "        )\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        return self.fc(self.conv(batch))\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X,y = batch\n",
    "        logits = self(X)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        pred = self(X)\n",
    "        val_loss = F.cross_entropy(pred, y)\n",
    "        val_acc = FM.accuracy(pred, y)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_acc\", val_acc)\n",
    "        return val_loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        pred = self(X)\n",
    "        acc = FM.accuracy(pred, y)\n",
    "        loss = F.cross_entropy(pred, y)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        self.log(\"test_acc\", acc)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.NAdam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name    | Type       | Params | In sizes          | Out sizes        \n",
      "--------------------------------------------------------------------------------\n",
      "0  | conv    | Sequential | 1.1 M  | [32, 1, 28, 28]   | [32, 256, 3, 3]  \n",
      "1  | conv.0  | Conv2d     | 3.2 K  | [32, 1, 28, 28]   | [32, 64, 24, 24] \n",
      "2  | conv.1  | ReLU       | 0      | [32, 64, 24, 24]  | [32, 64, 24, 24] \n",
      "3  | conv.2  | MaxPool2d  | 0      | [32, 64, 24, 24]  | [32, 64, 12, 12] \n",
      "4  | conv.3  | Conv2d     | 73.9 K | [32, 64, 12, 12]  | [32, 128, 12, 12]\n",
      "5  | conv.4  | ReLU       | 0      | [32, 128, 12, 12] | [32, 128, 12, 12]\n",
      "6  | conv.5  | Conv2d     | 147 K  | [32, 128, 12, 12] | [32, 128, 12, 12]\n",
      "7  | conv.6  | ReLU       | 0      | [32, 128, 12, 12] | [32, 128, 12, 12]\n",
      "8  | conv.7  | MaxPool2d  | 0      | [32, 128, 12, 12] | [32, 128, 6, 6]  \n",
      "9  | conv.8  | Conv2d     | 295 K  | [32, 128, 6, 6]   | [32, 256, 6, 6]  \n",
      "10 | conv.9  | ReLU       | 0      | [32, 256, 6, 6]   | [32, 256, 6, 6]  \n",
      "11 | conv.10 | Conv2d     | 590 K  | [32, 256, 6, 6]   | [32, 256, 6, 6]  \n",
      "12 | conv.11 | ReLU       | 0      | [32, 256, 6, 6]   | [32, 256, 6, 6]  \n",
      "13 | conv.12 | MaxPool2d  | 0      | [32, 256, 6, 6]   | [32, 256, 3, 3]  \n",
      "14 | fc      | Sequential | 303 K  | [32, 256, 3, 3]   | [32, 10]         \n",
      "15 | fc.0    | Flatten    | 0      | [32, 256, 3, 3]   | [32, 2304]       \n",
      "16 | fc.1    | Linear     | 295 K  | [32, 2304]        | [32, 128]        \n",
      "17 | fc.2    | ReLU       | 0      | [32, 128]         | [32, 128]        \n",
      "18 | fc.3    | Dropout    | 0      | [32, 128]         | [32, 128]        \n",
      "19 | fc.4    | Linear     | 8.3 K  | [32, 128]         | [32, 64]         \n",
      "20 | fc.5    | ReLU       | 0      | [32, 64]          | [32, 64]         \n",
      "21 | fc.6    | Dropout    | 0      | [32, 64]          | [32, 64]         \n",
      "22 | fc.7    | Linear     | 650    | [32, 64]          | [32, 10]         \n",
      "--------------------------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1927: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:03<00:00,  3.30s/it, loss=2.31, v_num=]\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "trainer = pl.Trainer(max_epochs=10, accelerator=\"gpu\", devices=1, fast_dev_run=True, callbacks=[ModelSummary(max_depth=-1)])\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | In sizes        | Out sizes      \n",
      "------------------------------------------------------------------------\n",
      "0 | conv | Sequential | 1.1 M  | [32, 1, 28, 28] | [32, 256, 3, 3]\n",
      "1 | fc   | Sequential | 303 K  | [32, 256, 3, 3] | [32, 10]       \n",
      "------------------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  10%|█         | 22/215 [05:35<49:01, 15.24s/it, loss=0.586, v_num=29] \n",
      "Epoch 0:   0%|          | 0/215 [00:40<?, ?it/s]\n",
      "Epoch 2: 100%|██████████| 215/215 [00:13<00:00, 16.08it/s, loss=0.388, v_num=30]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                                                                    \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                                                                     \t|  -              \t|  26578          \t|  49.063         \t|  100 %          \t|\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                                                        \t|  12.849         \t|  3              \t|  38.547         \t|  78.566         \t|\n",
      "|  on_train_batch_end                                                                                                                                                                                        \t|  0.029667       \t|  645            \t|  19.135         \t|  39.001         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_end                 \t|  3.427          \t|  3              \t|  10.281         \t|  20.955         \t|\n",
      "|  run_training_batch                                                                                                                                                                                        \t|  0.0098698      \t|  645            \t|  6.366          \t|  12.975         \t|\n",
      "|  [LightningModule]Classifier.optimizer_step                                                                                                                                                                \t|  0.0095287      \t|  645            \t|  6.146          \t|  12.527         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                                                                   \t|  0.002938       \t|  645            \t|  1.895          \t|  3.8624         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                                                              \t|  0.0025209      \t|  645            \t|  1.626          \t|  3.3141         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                                                            \t|  0.00055504     \t|  645            \t|  0.358          \t|  0.72967        \t|\n",
      "|  on_train_batch_start                                                                                                                                                                                      \t|  0.00033488     \t|  645            \t|  0.216          \t|  0.44025        \t|\n",
      "|  [LightningModule]Classifier.optimizer_zero_grad                                                                                                                                                           \t|  0.00028682     \t|  645            \t|  0.185          \t|  0.37707        \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_batch_start                                                                                                                                                    \t|  2.4806e-05     \t|  645            \t|  0.016          \t|  0.032611       \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                                                           \t|  2.4806e-05     \t|  645            \t|  0.016          \t|  0.032611       \t|\n",
      "|  [Callback]ModelSummary.on_batch_end                                                                                                                                                                       \t|  2.4806e-05     \t|  645            \t|  0.016          \t|  0.032611       \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                                                       \t|  2.3256e-05     \t|  645            \t|  0.015          \t|  0.030573       \t|\n",
      "|  [LightningModule]Classifier.training_step_end                                                                                                                                                             \t|  2.3256e-05     \t|  645            \t|  0.015          \t|  0.030573       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_backward                 \t|  2.3256e-05     \t|  645            \t|  0.015          \t|  0.030573       \t|\n",
      "|  [LightningModule]Classifier.configure_callbacks                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.prepare_data                                                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_accelerator_backend_setup                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_accelerator_backend_setup                                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_accelerator_backend_setup                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': None}.on_before_accelerator_backend_setup\t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                                                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.setup                                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': None}.setup                              \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.setup                                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.configure_sharded_model                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_configure_sharded_model                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_configure_sharded_model                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_configure_sharded_model                                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_configure_sharded_model         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.configure_optimizers                                                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_fit_start                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_start                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_fit_start                                                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_pretrain_routine_start                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_pretrain_routine_start                                                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_pretrain_routine_start                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_pretrain_routine_start          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_pretrain_routine_start                                                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_pretrain_routine_end                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_pretrain_routine_end                                                                                                                                                            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_pretrain_routine_end                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_pretrain_routine_end            \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_pretrain_routine_end                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_train_dataloader                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                                                                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_start                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_start                     \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_train_start                                                                                                                                                                \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                                                             \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_epoch_start                                                                                                                                                                  \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_epoch_start                                                                                                                                                                     \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_epoch_start                                                                                                                                                    \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_epoch_start                     \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_epoch_start                                                                                                                                                                \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                                                            \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                                                               \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_epoch_start                                                                                                                                              \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_epoch_start               \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_train_epoch_start                                                                                                                                                          \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_batch_start                                                                                                                                                                  \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_batch_start                                                                                                                                                                     \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_batch_start                     \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_train_batch_start                                                                                                                                                          \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step_end                                                                                                                                                          \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                                                             \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                                                                \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_zero_grad                                                                                                                                               \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_zero_grad                \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_before_zero_grad                                                                                                                                                           \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                                                              \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                                                                 \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_backward                                                                                                                                                \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_before_backward                                                                                                                                                            \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                                                               \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                                                                  \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_after_backward                                                                                                                                                 \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_after_backward                  \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_after_backward                                                                                                                                                             \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                                                        \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_before_optimizer_step                                                                                                                                          \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_before_optimizer_step           \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_before_optimizer_step                                                                                                                                                      \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_train_batch_end                                                                                                                                                            \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_batch_end                                                                                                                                                                    \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_batch_end                                                                                                                                                      \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_batch_end                       \t|  0.0            \t|  645            \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                                                              \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                                                                 \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_epoch_end                                                                                                                                                \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                                                              \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                                                                 \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_save_checkpoint                                                                                                                                                \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_save_checkpoint                 \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_save_checkpoint                                                                                                                                                            \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_train_epoch_end                                                                                                                                                            \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_epoch_end                                                                                                                                                                    \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_epoch_end                                                                                                                                                                       \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_epoch_end                                                                                                                                                      \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_epoch_end                       \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_epoch_end                                                                                                                                                                  \t|  0.0            \t|  3              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                                                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_train_end                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_train_end                       \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_train_end                                                                                                                                                                  \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                                                               \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                                                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.on_fit_end                                                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.on_fit_end                         \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.on_fit_end                                                                                                                                                                    \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                                                        \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                                                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]GradientAccumulationScheduler.teardown                                                                                                                                                          \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None, 'save_on_train_epoch_end': True}.teardown                           \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "|  [LightningModule]Classifier.teardown                                                                                                                                                                      \t|  0.0            \t|  1              \t|  0.0            \t|  0.0            \t|\n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "trainer = pl.Trainer(max_epochs=3, accelerator=\"gpu\", devices=1, profiler=\"simple\")\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.profiler import AdvancedProfiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | In sizes        | Out sizes      \n",
      "------------------------------------------------------------------------\n",
      "0 | conv | Sequential | 1.1 M  | [32, 1, 28, 28] | [32, 256, 3, 3]\n",
      "1 | fc   | Sequential | 303 K  | [32, 256, 3, 3] | [32, 10]       \n",
      "------------------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 215/215 [00:12<00:00, 16.80it/s, loss=0.402, v_num=31]\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "# trainer = pl.Trainer(max_epochs=3, accelerator=\"gpu\", devices=1, profiler=\"advanced\")\n",
    "profiler = AdvancedProfiler(dirpath=\".\", filename=\"perf_logs\")\n",
    "trainer = pl.Trainer(max_epochs=3, accelerator=\"gpu\", devices=1, profiler=profiler)\n",
    "trainer.fit(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerator usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py:133: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type       | Params | In sizes        | Out sizes      \n",
      "------------------------------------------------------------------------\n",
      "0 | conv | Sequential | 1.1 M  | [32, 1, 28, 28] | [32, 256, 3, 3]\n",
      "1 | fc   | Sequential | 303 K  | [32, 256, 3, 3] | [32, 10]       \n",
      "------------------------------------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.655     Total estimated model params size (MB)\n",
      "d:\\conda\\envs\\torch-light\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 215/215 [00:14<00:00, 14.66it/s, loss=0.43, v_num=34] \n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import DeviceStatsMonitor\n",
    "\n",
    "model = Classifier()\n",
    "trainer  = pl.Trainer(max_epochs=3, accelerator=\"gpu\", callbacks=[DeviceStatsMonitor()])\n",
    "trainer.fit(model, train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch-light')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9675ec75ae99c53675dd696ee3c9dea8ffb376bcdb5a2840f20b4a4f8f01a32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
